# MOLLM

This repository contains the source code and scripts for the MOLLM project. The project is organized as follows:

## Project Structure

/home/v-nianran/src/MOLLM <br>
â”œâ”€â”€ algorithm <br>
â”‚ â”œâ”€â”€ base.py <br>
â”‚ â”œâ”€â”€ MOO.py <br>
â”‚ â””â”€â”€  PromptTemplate.py <br>
â”œâ”€â”€ data <br>
â”‚ â”œâ”€â”€ data_goal5.json <br>
â”‚ â””â”€â”€ zinc.tab <br>
â”œâ”€â”€ problem <br>
â”‚ â”œâ”€â”€ molecules <br>
â”‚ â”‚ â”œâ”€â”€ evaluator.py <br>
â”‚ â”‚ â”œâ”€â”€ goal5_gemini.yaml <br>
â”‚ â”‚ â””â”€â”€ molecule.yaml <br>
â”œâ”€â”€ eval.py <br>
â”œâ”€â”€ main.py <br>
â””â”€â”€ test.ipynb <br>

### Running the experiments
  - `python main.py molecules/goal5_gemini.yaml`: You need to define a config file to run, this is an example, you can use it as a template, the path is set to under the problem directory.

### Description of Files and Directories

- **main.py**
  - The main entry point for training and testing the MOLLM model.

- **model/**
  - `MOLLM.py`: Contains the implementation of the MOLLM model.
  - `LLM.py`: Implemetation of LLM model
  - `MOScigpt.py`: MO SciGPT model and its algorithm.
  - `load_Scigpt.py`: Utility script to load the SciGPT model.
  - `util.py`: Utility functions used across the project, including NSGA-II currently.

- **test.ipynb**
  - Jupyter notebook containing experiments, visualizations, or other exploratory analysis related to the MOLLM project.
  - Including the tutorial of how to modify the main components

## Getting Started

# ğŸ§¬ YAML File Specification for Multi-Objective Molecular Optimization

This project uses a structured YAML format to define tasks for multi-objective molecular optimization. Each YAML file outlines the task description, output format, mutation/crossover guidelines, and optimization objectives. This format ensures consistency and clarity when interfacing with molecule generation and optimization models.

---

## ğŸ“ File Structure Overview

A standard YAML file should contain the following fields:

| Field Name              | Required | Description |
|-------------------------|----------|-------------|
| `description`           | âœ…       | A brief overview of the task; describe what the model should achieve |
| `example_output`        | âœ…       | Defines the expected output format (must include `<candidate>` tags and your answer format) |
| `mutation_instruction`  | â­•       | Suggested mutation operations to guide molecule structure changes |
| `crossover_instruction` | â­•       | Suggested crossover operations (optional, can be left empty) |
| `other_requirements`    | â­•       | Any additional constraints, e.g., "Molecules must be valid" |
| Optimization Objectives (e.g. `qed`, `sa`) | âœ… | One or more task-specific objectives, each described in a dedicated field |

---

## ğŸ“ Example YAML File (problem/molecules/molecule.yaml)

```yaml
description: This task is to propose better molecules according to multiple objectives.

example_output: 'Each output new candidate must start with <candidate> and end with </candidate> in SMILES format. Example: <candidate>c1ccccc1</candidate>'

mutation_instruction: 'Example operations include:
  1. Modify functional groups
  2. Replace atoms or bonds
  3. Add/remove small substituents
  4. Ring modifications
  5. Stereochemistry changes
  6. Property-specific optimizations
  '

crossover_instruction: ''

other_requirements: The output molecules should be valid.

qed: QED (Quantitative Estimate of Drug-likeness) is a measure that quantifieshow
  'drug-like' a molecule is based on properties such as molecular weight,solubility,
  and the number of hydrogen bond donors and acceptors.Adding functional groups that
  improve drug-like properties (e.g., small molecular size,balanced hydrophilicity)
  can increase QED, while introducing large, complex, or highly polar groups can decrease
  it.
logp: LogP is the logarithm of the partition coefficient, measuring the lipophilicityor
  hydrophobicity of a molecule, indicating its solubility in fats versus water.Adding
  hydrophobic groups (e.g., alkyl chains or aromatic rings) increases LogP,while adding
  polar or hydrophilic groups (e.g., hydroxyl or carboxyl groups) decreases it.
```

# ğŸ“Š Evaluator Guide

In each specific problem directory under `problem/`, you need to create an `evaluator.py` file to define a custom evaluation logic. This file should contain a class named `RewardingSystem` that evaluates the quality of generated results.

---

## âœ… Required Structure

The `evaluator.py` file **must** define the following structure:

```python
class RewardingSystem:
    def __init__(self, config):
        # Initialization method (config is passed in)
        pass

    def evaluate(self, items):
        # Main evaluation function
        pass
```

---

## ğŸ§© Input and Output of `evaluate`

* **Input**: `items` is a list of Item objects (algorithm.base.Item). Each dictionary represents a result item to evaluate.
* **Each item must be given a dict containing the following keys**:

| Key                   | Description                                                                                                |
|----------------------|------------------------------------------------------------------------------------------------------------|
| `original_results`    | The raw metrics (e.g., `{'sa': 2.22, 'qed': 0.68}`). These are used for logging or visualization.          |
| `transformed_results` | The normalized and minimized version of the original results. Values must be in the `[0, 1]` range.        |
| `overall_score`       | A scalar value representing the overall quality of the item. Higher is better. This is fully customizable. |

* **Then simply use item.assign_results(results) to assign the result to each item**
* **No output needed to be returned**
---

## ğŸ”„ About `transformed_results`

You need to manually normalize and transform the original results so they are suitable for multi-objective optimization. The general rules are:

1. **Normalization**: All values must be in the range `[0, 1]`.
2. **Minimization Format**: The optimization system assumes all objectives are "to minimize". You should convert maximization metrics accordingly.

### Example Transformation

Assume you are working with:

- **QED** (Quantitative Estimate of Drug-likeness): originally a maximization metric in `[0, 1]`  
  â†’ Transformation: `1 - qed`
- **SA** (Synthetic Accessibility): originally a minimization metric, roughly in `[0, 10]`  
  â†’ Transformation: `sa / 10`

```python
transformed_results = {
    'sa': original['sa'] / 10,
    'qed': 1 - original['qed']
}
```

---

## ğŸ“ˆ Defining `overall_score`

You must define a scalar score (`overall_score`) for each item. This value will be used for sorting and comparison â€” **the higher, the better**.

### Equal-weight example:

```python
overall_score = len(transformed_results) - np.sum(list(transformed_results.values()))
```

### Custom weighted example:

```python
weights = {'qed': 0.7, 'sa': 0.3}
overall_score = 1 - (weights['qed'] * transformed_results['qed'] +
                     weights['sa'] * transformed_results['sa'])
```

You are free to implement any custom scoring logic as long as the final result is a single float value.

---

## ğŸ“ File Placement

Your `evaluator.py` file should be placed in the corresponding problem directory, example:

```
problem/
â””â”€â”€ molecules/
    â”œâ”€â”€ evaluator.py  âœ…
    â””â”€â”€ config.yaml
```

---

## ğŸ§ª Sample `evaluator.py` Template

```python
import numpy as np

class RewardingSystem:
    def __init__(self, config):
        self.config = config

    def evaluate(self, items):
        for item in items:
            original = item['original_results']

            # Transform metrics
            transformed = {
                'sa': original['sa'] / 10,
                'qed': 1 - original['qed']
            }

            # Save transformed results
            item['transformed_results'] = transformed

            # Compute overall_score (equal-weight example)
            item['overall_score'] = len(transformed) - np.sum(list(transformed.values()))
            item.assign_results(results)
```

---

## â—Notes

- `evaluate()` modifies each `item` in-place.
- `transformed_results` must include normalized and minimization-converted values.
- `overall_score` must be a scalar float, with **higher values indicating better results**.
- You are free to extend the evaluation logic as needed per problem.

---
