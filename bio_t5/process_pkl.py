import pickle
import json
import uuid
import pandas as pd
from rdkit import Chem
import selfies as sf
import re
import os
import pickle 

tox21_name_dict = {
    "NR-AR": "Androgen Receptor (AR)",
    "NR-AR-LBD": "Androgen Receptor (AR) Ligand-Binding Domain (LBD)",
    "NR-AhR": "Aryl hydrocarbon Receptor (AhR)",
    "NR-Aromatase": "Aromatase receptor",
    "NR-ER": "Estrogen Receptor (ER)",
    "NR-ER-LBD": "Estrogen Receptor (ER) Ligand-Binding Domain (LBD)",
    "NR-PPAR-gamma": "Peroxisome Proliferator-Activated Receptor Gamma (PPAR-gamma)",
    "SR-ARE": "Antioxidant Responsive Element (ARE)",
    "SR-ATAD5": "ATAD5 (ATPase Family AAA Domain Containing 5) gene",
    "SR-HSE": "Heat Shock Sequence (HSE) elements",
    "SR-MMP": "Mitochondrial Membrane Potential (MMP)",
    "SR-p53": "p53 pathway",
}

def transform_key(key):
    return 'tox21_' + key.lower().replace('-', '_')

trm_tox21_name_dict = {transform_key(key): value for key, value in tox21_name_dict.items()}

task_dir='tasks'
os.makedirs(task_dir, exist_ok=True)

def to_json(data_list, name, task_num="1800", dataset_name='bbbp'):
    data = {}
    data['Contributors'] = ['Qizhi Pei']
    data['Categories'] = ['Classification']
    data['Reasoning'] = []
    data['URL'] = ['https://deepchem.readthedocs.io/en/latest/api_reference/moleculenet.html']
    data['Instruction_language'] = ['English']
    data['Domains'] = ['Chemistry']
    data['Positive Examples'] = []
    data['Negative Examples'] = []
    data['Instances'] = []

    data['Source'] = ['Predict the property of the given molecule.']

    if dataset_name == 'bbbp':
        general_task_definition = f"Molecule property prediction task (a binary classification task) for the BBBP dataset. "
        dataset_desc = "The blood-brain barrier penetration (BBBP) dataset is designed for the modeling and prediction of barrier permeability. "
        instruction = "If the given molecule can penetrate the blood-brain barrier, "
    elif dataset_name == 'bace':
        general_task_definition = f"Molecule property prediction task (a binary classification task) for the BACE dataset. "
        dataset_desc = "The BACE dataset provides qualitative (binary label) binding results for a set of inhibitors of human beta-secretase 1 (BACE-1). "
        instruction = "If the given molecule can inhibit BACE-1, "
    elif dataset_name == 'clintox_ct_tox':
        general_task_definition = f"Molecule property prediction task (a binary classification task) for the ClinTox dataset. "
        dataset_desc = "The ClinTox dataset compares drugs approved by the FDA and drugs that have failed clinical trials for toxicity reasons. "
        instruction = "If the given molecule is toxic, "
    elif 'tox21' in dataset_name:
        general_task_definition = f"Molecule property prediction task (a binary classification task) for the Tox21 dataset. "
        dataset_desc = "The Tox21 dataset contains qualitative toxicity measurements for 8k compounds on 12 different targets, including nuclear receptors and stress response pathways. "
        if dataset_name == 'tox21_sr_atad5':
            instruction = f"If the given molecule can affect {trm_tox21_name_dict['tox21_sr_atad5']}, "
        elif dataset_name == 'tox21_sr_mmp':
            instruction = f"If the given molecule can change {trm_tox21_name_dict['tox21_sr_mmp']}, "
        else:
            instruction = f"If the given molecule can activate {trm_tox21_name_dict[dataset_name]}, "
    else:
        raise NotImplementedError

    cls_definition = f"indicate via \"Yes\". Otherwise, response via \"No\"."
    data['Definition'] = [general_task_definition + dataset_desc + instruction + cls_definition]
    data['Input_language'] = ['English']
    data['Output_language'] = ['English']
    # Each instance must have a unique id, which should be the task number plus a string generated by uuid.uuid4().hex. E.g., task1356-bb5ff013dc5d49d7a962e85ed1de526b.
    for row in data_list:
        data['Instances'].append({
            'id': f'{task_num}-{uuid.uuid4().hex}',
            'input': "Molecule: " + row,
            'output': ["Yes."]
        })
         
    data['Instance License'] = ['Unknown']

    with open(f'{name}.json', 'w') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def rm_map_number(smiles):
    t = re.sub(':\d*', '', smiles)
    return t

def canonicalize(smiles):
    try:
        smiles = rm_map_number(smiles)
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None
        else:
            return Chem.MolToSmiles(mol)
    except:
        return None

def smiles_to_selfies(smiles):
    return sf.encoder(smiles, strict=False)

res = 'increase_bbbp'
data_pick = pickle.load(open(f'test.instruct.{res}.tsv.response.pkl', 'rb'))

invalid_count = 0
output = []
for item in data_pick:
    pred = item[1][0].strip('.')
    pred = pred.replace('<mol>', '').replace('</mol>', '')
    pred = pred.replace('<m>', '').replace(' ', '')
    pred_smi_can = canonicalize(pred)
    if pred_smi_can is None:
        invalid_count += 1
        continue
    pred_sfi = smiles_to_selfies(pred_smi_can)
    pred_sfi = '<bom>' + pred_sfi + '<eom>'
    output.append(pred_sfi)

print(f'Total {res}:', len(data_pick))
print(f'Invalid {res}:', invalid_count)

to_json(output, f'{task_dir}/{res}', task_num="1", dataset_name='bbbp')

os.makedirs(f'splits/{res}', exist_ok=True)

string_to_write = f"{res}"

for split in ['train', 'validation', 'test']:
    with open(f'splits/{res}/{split}_tasks.txt', 'w', encoding='utf-8') as file:
        file.write(string_to_write)
