# @package _global_

mode: 'ft'

predict_only: true

model:
  name: 'google/t5-v1_1-base'
  checkpoint_path: '/protein/users/v-qizhipei/checkpoints/unimpt/finetune_mol_text_A100_step50k_nolap_0529/checkpoint-ft-35000/pytorch_model.bin'
  dropout: 0.0
  random_init: false
  compile: false # Pytorch 2.0

data:
  max_seq_len: 512
  max_target_len: 512
  max_num_instances_per_task: 100000
  add_task_name: False
  add_task_definition: True
  num_pos_examples: 0
  num_neg_examples: 0
  add_explanation: False
  tk_instruct: False
  exec_file_path: utils/ni_dataset.py
  data_dir: /protein/users/v-qizhipei/data/unimpt_finetune/splits/mol_text/mol2text
  task_dir: /protein/users/v-qizhipei/data/unimpt_finetune/tasks

optim:
  name: adamw
  base_lr: 1e-3
  batch_size: 128
  epochs: -1
  total_steps: 50000
  warmup_steps: 1000
  lr_scheduler: cosine
  weight_decay: 0.0
  grad_clip: 0.0
  grad_acc: 1
  test_bsz_multi: 1

eval:
  every_steps: 1000
  steps: 100000 # whole test set

pred:
  every_steps: 1000

checkpoint:
  every_steps: 5000

hydra:
  job:
    chdir: True
  run:
    dir: ./logs/eval_mol2text

test_task: mol2text
result_fn: test_mol2text_pred.tsv