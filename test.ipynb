{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    #property_list = ['qed', 'logp', 'donor']\n",
    "\n",
    "    def __init__(self, value, property_list):\n",
    "        self.value = value\n",
    "        self.property_list = property_list if property_list is not None else self.property_list\n",
    "        # raw scores are the original objective values\n",
    "        self.raw_scores = [ 0 for prop in self.property_list]\n",
    "        # scores are the objective values (after judgement) for MOO\n",
    "        self.scores = [ 0 for prop in self.property_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_donor(  requirement, simi_requirement, similarity, donor_input_mol, donor_response_mol, delta= 1e-9 ):\n",
    "    if requirement == 'increase':\n",
    "        return (donor_response_mol > donor_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (donor_response_mol < donor_input_mol - delta  and similarity>simi_requirement)\n",
    "    if requirement == 'the same':        \n",
    "        return (abs(donor_input_mol - donor_response_mol) < delta and similarity>simi_requirement)\n",
    "    if requirement == 'increase, >=2':\n",
    "        return (donor_response_mol - donor_input_mol >= 2 and similarity>simi_requirement)\n",
    "    if requirement == 'decrease, >=2':\n",
    "        return (donor_input_mol - donor_response_mol>=2 and similarity>simi_requirement)\n",
    "        \n",
    "    raise ValueError(f'Invalid requirement: {requirement}')\n",
    "\n",
    "def judge_qed(  requirement, simi_requirement, similarity, qed_input_mol, qed_response_mol, delta=1e-9 ):\n",
    "    if abs(qed_response_mol) == 0:\n",
    "        return False\n",
    "    if requirement == 'increase':\n",
    "        return (qed_response_mol > qed_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (qed_response_mol < qed_input_mol - delta and similarity>simi_requirement)\n",
    "    if requirement == 'increase, >=0.1':\n",
    "        return ( qed_response_mol - qed_input_mol >= 0.1 and similarity>simi_requirement)\n",
    "    if requirement == 'decrease, >=0.1':\n",
    "        return ( qed_input_mol - qed_response_mol >= 0.1 and similarity>simi_requirement)\n",
    "    raise ValueError(f'Invalid requirement: {requirement}')\n",
    "\n",
    "def judge_logp(  requirement, simi_requirement, similarity, logp_input_mol, logp_response_mol, delta=1e-9 ):\n",
    "    if abs(logp_response_mol) == 100:\n",
    "        return False\n",
    "    if requirement == 'increase':\n",
    "        return (logp_response_mol > logp_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (logp_response_mol < logp_input_mol - delta and similarity>simi_requirement)\n",
    "    if 'range,' in requirement:\n",
    "        a, b = [int(x) for x in requirement.split(',')[1:]]\n",
    "        return (a<=logp_response_mol<=b and similarity>simi_requirement)\n",
    "    raise ValueError(f'Invalid requirement: {requirement}')\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 定义 API 端点 URL\n",
    "url = 'http://cpu1.ms.wyue.site:8000/process'\n",
    "\n",
    "\n",
    "def get_evaluation(evaluate_metric, smiles):\n",
    "    data = {\n",
    "        \"ops\": evaluate_metric,\n",
    "        \"data\":smiles\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    result = response.json()['results']\n",
    "    return result\n",
    "\n",
    "def mean_sr(r):\n",
    "    return r.mean(), (r>0).sum()/len(r)\n",
    "def eval_mo_results(df,similarity_requ=0.4,length=99999,ops=['qed','logp','donor'],qed_meta=None,logp_meta=None,donor_meta=None,candidate_num=20):\n",
    "    #key = 'mo_gpt4_direct_wo_history'\n",
    "    #similarity_requ = 0.4\n",
    "    hist_success_times = []\n",
    "    for index,row in tqdm(df[:length].iterrows()):\n",
    "        mol = row['input_mol']\n",
    "        #print(mol)\n",
    "        combine_mols = [[mol,row[f'response{i+1}']] for i in range(candidate_num)]\n",
    "        eval_res = get_evaluation(['similarity']+ops,combine_mols)\n",
    "        #print(eval_res)\n",
    "        if 'donor' in ops:\n",
    "            input_mol_donor = eval_res['donor'][0][0]\n",
    "        if 'qed' in ops:\n",
    "            input_mol_qed = eval_res['qed'][0][0]\n",
    "        if 'logp' in ops:\n",
    "            input_mol_logp = eval_res['logp'][0][0]\n",
    "        success_times = 0\n",
    "        for i in range(candidate_num):\n",
    "            if len(ops) == 3:\n",
    "                if judge_donor(donor_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_donor,eval_res['donor'][i][1]) and \\\n",
    "                    judge_logp(logp_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_logp,eval_res['logp'][i][1]) and \\\n",
    "                    judge_qed(qed_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_qed,eval_res['qed'][i][1]):\n",
    "                    success_times += 1\n",
    "            elif len(ops)==1 and ops[0]=='qed' and judge_qed(qed_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_qed,eval_res['qed'][i][1]):\n",
    "                success_times+=1\n",
    "            elif len(ops)==1 and ops[0]=='logp' and judge_logp(logp_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_logp,eval_res['logp'][i][1]):\n",
    "                success_times+=1\n",
    "            elif len(ops)==1 and ops[0]=='donor' and judge_donor(donor_meta[index]['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_donor,eval_res['donor'][i][1]):\n",
    "                success_times+=1\n",
    "        #print('success times:',success_times)\n",
    "        hist_success_times.append(success_times)\n",
    "    return np.array(hist_success_times)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obj['final_pops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qed_requ': {'source_smiles': 'O=C([C@H]1CCCC[C@H]1N1CCCC1=O)N1CC2(CC(F)C2)C1',\n",
       "   'reference_smiles': 'NNC(=O)C(=O)NC1CC2(C1)CN(C(=O)[C@H]1CCCC[C@H]1N1CCCC1=O)C2',\n",
       "   'property': 'QED',\n",
       "   'requirement': 'decrease'},\n",
       "  'logp_requ': {'source_smiles': 'CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1',\n",
       "   'reference_smiles': 'COc1ccc([C@@H](O)C(=O)N[C@H]2[C@@H]3COC[C@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1',\n",
       "   'property': 'logP',\n",
       "   'requirement': 'range, 2, 3'},\n",
       "  'donor_requ': {'source_smiles': 'O=C(NC[C@H]1CCOc2ccccc21)c1ccc(F)c(C(F)(F)F)c1',\n",
       "   'reference_smiles': 'CC(C)C[NH+](CC(=O)[O-])C(F)(F)c1cc(C(=O)NC[C@H]2CCOc3ccccc32)ccc1F',\n",
       "   'property': 'donor',\n",
       "   'requirement': 'increase'}},\n",
       " {'qed_requ': {'source_smiles': 'CC(C)c1cccc(N(C)CCN(C)C(=O)CCNc2cc(-c3ccsc3)cc(-c3cccc(O)c3)n2)c1',\n",
       "   'reference_smiles': 'CN(C)CCN(C)C(=O)CCNc1cc(-c2ccsc2)cc(-c2cccc(O)c2)n1',\n",
       "   'property': 'QED',\n",
       "   'requirement': 'increase, >=0.1'},\n",
       "  'logp_requ': {'source_smiles': 'CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)CCl)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12',\n",
       "   'reference_smiles': 'CC=C(C=CC(=C(C)CC)N1CCOC(CO)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12',\n",
       "   'property': 'logP',\n",
       "   'requirement': 'decrease'},\n",
       "  'donor_requ': {'source_smiles': 'Cc1ccc2ncc(CN3CCC[C@H]3c3cccc(N(C)C)c3)n2c1',\n",
       "   'reference_smiles': 'CN(C)c1cccc([C@@H]2CCCN2Cc2cnc3ccc(C4CCCCCCC4)cn23)c1',\n",
       "   'property': 'donor',\n",
       "   'requirement': 'the same'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/home/v-nianran/src/MOLLM/data/uniform150_test.json', 'r') as json_file:\n",
    "    dataset= json.load(json_file)\n",
    "dataset['requirements'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_donor(  requirement, simi_requirement, similarity, donor_input_mol, donor_response_mol, delta= 1e-9 ):\n",
    "    if requirement == 'increase':\n",
    "        return (donor_response_mol > donor_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (donor_response_mol < donor_input_mol - delta  and similarity>simi_requirement)\n",
    "    if requirement == 'the same':        \n",
    "        return (abs(donor_input_mol - donor_response_mol) < delta and similarity>simi_requirement)\n",
    "    if requirement == 'increase, >=2':\n",
    "        return (donor_response_mol - donor_input_mol >= 2 and similarity>simi_requirement)\n",
    "    if requirement == 'decrease, >=2':\n",
    "        return (donor_input_mol - donor_response_mol>=2 and similarity>simi_requirement)\n",
    "        \n",
    "    raise ValueError(f'Invalid requirement: {requirement}')\n",
    "\n",
    "def judge_qed(  requirement, simi_requirement, similarity, qed_input_mol, qed_response_mol, delta=1e-9 ):\n",
    "    if abs(qed_response_mol) == 0:\n",
    "        return False\n",
    "    if requirement == 'increase':\n",
    "        return (qed_response_mol > qed_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (qed_response_mol < qed_input_mol - delta and similarity>simi_requirement)\n",
    "    if requirement == 'increase, >=0.1':\n",
    "        return ( qed_response_mol - qed_input_mol >= 0.1 and similarity>simi_requirement)\n",
    "    if requirement == 'decrease, >=0.1':\n",
    "        return ( qed_input_mol - qed_response_mol >= 0.1 and similarity>simi_requirement)\n",
    "    raise ValueError(f'Invalid requirement: {requirement}')\n",
    "\n",
    "def judge_logp(  requirement, simi_requirement, similarity, logp_input_mol, logp_response_mol, delta=1e-9 ):\n",
    "    if abs(logp_response_mol) == 100:\n",
    "        return False\n",
    "    if requirement == 'increase':\n",
    "        return (logp_response_mol > logp_input_mol + delta and similarity>simi_requirement)\n",
    "    if requirement == 'decrease':\n",
    "        return (logp_response_mol < logp_input_mol - delta and similarity>simi_requirement)\n",
    "    if 'range,' in requirement:\n",
    "        a, b = [int(x) for x in requirement.split(',')[1:]]\n",
    "        return (a<=logp_response_mol<=b and similarity>simi_requirement)\n",
    "    raise ValueError(f'Invalid requirement: {requirement}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "url = 'http://cpu1.ms.wyue.site:8000/process'\n",
    "import time\n",
    "\n",
    "def get_evaluation(evaluate_metric, smiles):\n",
    "    data = {\n",
    "        \"ops\": evaluate_metric,\n",
    "        \"data\":smiles\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    result = response.json()['results']\n",
    "    return result\n",
    "\n",
    "def extract_smiles_from_string(text):\n",
    "    pattern = r\"<mol>(.*?)</mol>\"\n",
    "    smiles_list = re.findall(pattern, text)\n",
    "    return smiles_list\n",
    "def eval_mo_results(dataset,obj,similarity_requ=0.4,ops=['qed','logp','donor'],candidate_num=20):\n",
    "    hist_success_times = []\n",
    "    prompts = dataset['prompts']\n",
    "    requs = dataset['requirements']\n",
    "    for index,prompt in tqdm(enumerate(prompts)):\n",
    "        mol = extract_smiles_from_string(prompt)[0]\n",
    "        #print(mol)\n",
    "        final_pops = obj['final_pops'][index]\n",
    "        combine_mols = [[mol, i.value] for i in final_pops]\n",
    "        eval_res = get_evaluation(['similarity']+ops,combine_mols)\n",
    "        #print(eval_res)\n",
    "        if 'donor' in ops:\n",
    "            input_mol_donor = eval_res['donor'][0][0]\n",
    "        if 'qed' in ops:\n",
    "            input_mol_qed = eval_res['qed'][0][0]\n",
    "        if 'logp' in ops:\n",
    "            input_mol_logp = eval_res['logp'][0][0]\n",
    "        success_times = 0\n",
    "        for i in range(candidate_num):\n",
    "            if len(ops) == 3:\n",
    "                if judge_donor(requs[index]['donor_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_donor,eval_res['donor'][i][1]) and \\\n",
    "                    judge_logp(requs[index]['logp_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_logp,eval_res['logp'][i][1]) and \\\n",
    "                    judge_qed(requs[index]['qed_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_qed,eval_res['qed'][i][1]):\n",
    "                    success_times += 1\n",
    "            elif len(ops)==1 and ops[0]=='qed' and judge_qed(requs[index]['qed_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_qed,eval_res['qed'][i][1]):\n",
    "                success_times+=1\n",
    "            elif len(ops)==1 and ops[0]=='logp' and judge_logp(requs[index]['logp_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_logp,eval_res['logp'][i][1]):\n",
    "                success_times+=1\n",
    "            elif len(ops)==1 and ops[0]=='donor' and judge_donor(requs[index]['donor_requ']['requirement'],similarity_requ,eval_res['similarity'][i],input_mol_donor,eval_res['donor'][i][1]):\n",
    "                success_times+=1\n",
    "        #print('success times:',success_times)\n",
    "        hist_success_times.append(success_times)\n",
    "    return np.array(hist_success_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:57,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filepath = '/home/v-nianran/src/results/donoruniform150.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "r = eval_mo_results(dataset,obj,similarity_requ=0.4,ops=['donor'],candidate_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:03,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qed'] (1.34, 0.3333333333333333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:05,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logp'] (1.8066666666666666, 0.38666666666666666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:58,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['donor'] (2.513333333333333, 0.9133333333333333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qed', 'logp'] (0.0, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/v-nianran/src/results/qed_donoruniform150.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exps:\n\u001b[1;32m     12\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/v-nianran/src/results/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform150.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m         obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     15\u001b[0m     r \u001b[38;5;241m=\u001b[39m eval_mo_results(dataset,obj,similarity_requ\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,ops\u001b[38;5;241m=\u001b[39me,candidate_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/v-nianran/src/results/qed_donoruniform150.pkl'"
     ]
    }
   ],
   "source": [
    "exps = [\n",
    "    ['qed'],\n",
    "    ['logp'],\n",
    "    ['donor'],\n",
    "    ['qed','logp'],\n",
    "    ['qed','donor'],\n",
    "    ['logp','donor'],\n",
    "    ['qed','logp','donor']\n",
    "]\n",
    "rs = []\n",
    "for e in exps:\n",
    "    filepath = '/home/v-nianran/src/results/' + '_'.join(e) + 'uniform150.pkl'\n",
    "    with open(filepath, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    r = eval_mo_results(dataset,obj,similarity_requ=0.4,ops=e,candidate_num=20)\n",
    "    print(e,mean_sr(r))\n",
    "    rs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:06,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logp', 'donor'] (0.0, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [01:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qed', 'logp', 'donor'] (0.7333333333333333, 0.25333333333333335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exps = [\n",
    "    ['logp','donor'],\n",
    "    ['qed','logp','donor']\n",
    "]\n",
    "for e in exps:\n",
    "    filepath = '/home/v-nianran/src/results/' + '_'.join(e) + 'uniform150.pkl'\n",
    "    with open(filepath, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    r = eval_mo_results(dataset,obj,similarity_requ=0.4,ops=e,candidate_num=20)\n",
    "    print(e,mean_sr(r))\n",
    "    rs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/v-nianran/src/results/donoruniform150.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "r = eval_mo_results(dataset,obj,similarity_requ=0.4,ops=['donor'],candidate_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.513333333333333, 0.9133333333333333)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_sr(r):\n",
    "    k = r.clip(0,5)\n",
    "    return k.mean(), (k>0).sum()/len(k)\n",
    "mean_sr(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''# Initial population data\n",
    "initial_qed = [i.fitness[0] for i in init_population]\n",
    "initial_sa = [i.logp for i in init_population]\n",
    "initial_donor = [i.donor_num for i in init_population]\n",
    "\n",
    "# Plot initial population\n",
    "plt.scatter(initial_qed, initial_sa, color='blue', label='Initial Population')\n",
    "\n",
    "# Plot initial population points with donor_num > 2 using a star marker\n",
    "for i in range(len(init_population)):\n",
    "    if initial_donor[i] > 2:\n",
    "        plt.scatter(initial_qed[i], initial_sa[i], color='yellow', marker='*')'''\n",
    "\n",
    "# Final population data\n",
    "population = final_pops[0]\n",
    "final_qed = [i.fitness[0] for i in population]\n",
    "final_sa = [i.logp for i in population]\n",
    "final_donor = [i.donor_num for i in population]\n",
    "\n",
    "# Plot final population\n",
    "plt.scatter(final_qed, final_sa, color='red', label='Final Population')\n",
    "\n",
    "# Plot final population points with donor_num > 2 using a star marker\n",
    "for i in range(len(population)):\n",
    "    if final_donor[i] > 2:\n",
    "        plt.scatter(final_qed[i], final_sa[i], color='yellow', marker='*')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('QED')\n",
    "plt.ylabel('Normalized SA')\n",
    "plt.legend()\n",
    "plt.title('Initial and Final Populations in QED vs. Normalized SA (without LLM, random generating new candidates)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewarding system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import get_evaluation\n",
    "class Rewarding_system:\n",
    "    def __init__(self):\n",
    "        self.all_rewards = {}\n",
    "\n",
    "    def register_reward(self, reward_name, reward_function):\n",
    "        self.all_rewards[reward_name] = reward_function\n",
    "\n",
    "    def get_reward(self, reward_name, items):\n",
    "        return self.all_rewards[reward_name](*items)\n",
    "\n",
    "    def evaluate(self,ops,smiles_list):\n",
    "        return get_evaluation(ops,smiles_list)\n",
    "\n",
    "    def evaluate_items(self, items, qed_requ, logp_requ, donor_requ, donor_num):\n",
    "        smiles_list = [[item.value] for item in items]\n",
    "        fitnesses, donors, logps, qeds = self._get_evaluation(smiles_list, qed_requ, logp_requ, donor_requ, donor_num)\n",
    "\n",
    "        for i, item in enumerate(items):\n",
    "            item.scores = {'qed': qeds[i], 'logp': logps[i], 'donor': donors[i]}\n",
    "            item.fitness = fitnesses[i]\n",
    "\n",
    "    def _get_evaluation(self, smiles_list, qed_requ, logp_requ, donor_requ, donor_num):\n",
    "        # 具体的评估函数与之前的类似\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "class History_Buffer:\n",
    "    def __init__(self):\n",
    "        self.prompts = []\n",
    "        self.generations = []\n",
    "        self.responses = []\n",
    "        self.save_path = 'checkpoint/'\n",
    "\n",
    "    def save_to_pkl(self, filename):\n",
    "        with open(os.path.join(self.save_path,filename), 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "    def load_from_pkl(self,filename):\n",
    "        with open(os.path.join(self.save_path,filename), 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "        print(f\"Data loaded from {filename}\")\n",
    "        return obj\n",
    "\n",
    "    def push(self,prompts,generation,responses):\n",
    "        self.prompts.append(prompts)\n",
    "        self.generations.append(generation)\n",
    "        self.responses.append(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import AzureCliCredential, ChainedTokenCredential, DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "class LLM:\n",
    "    def __init__(self,model='chatgpt'):\n",
    "        self.model_choice = model\n",
    "        self.model = self._init_model(model)\n",
    "        self.chat = self._init_chat(model)\n",
    "\n",
    "    def _init_chat(self,model):\n",
    "        if model == 'chatgpt':\n",
    "            return self.gpt_chat\n",
    "\n",
    "    def _init_model(self,model):\n",
    "        if model == 'chatgpt':\n",
    "            return self._init_chatgpt()\n",
    "\n",
    "    def _init_chatgpt(self):\n",
    "        # Set the necessary variables\n",
    "        resource_name = \"gcrgpt4aoai2c\"\n",
    "        endpoint = f\"https://{resource_name}.openai.azure.com/\"\n",
    "        api_version = \"2024-02-15-preview\"  # Replace with the appropriate API version\n",
    "\n",
    "        azure_credential = ChainedTokenCredential(\n",
    "            AzureCliCredential(),\n",
    "            DefaultAzureCredential(\n",
    "                exclude_cli_credential=True,\n",
    "                # Exclude other credentials we are not interested in.\n",
    "                exclude_environment_credential=True,\n",
    "                exclude_shared_token_cache_credential=True,\n",
    "                exclude_developer_cli_credential=True,\n",
    "                exclude_powershell_credential=True,\n",
    "                exclude_interactive_browser_credential=True,\n",
    "                exclude_visual_studio_code_credentials=True,\n",
    "                managed_identity_client_id=os.environ.get(\"DEFAULT_IDENTITY_CLIENT_ID\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        token_provider = get_bearer_token_provider(azure_credential,\n",
    "            \"https://cognitiveservices.azure.com/.default\")\n",
    "        client = AzureOpenAI(\n",
    "            api_version=api_version,\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=token_provider\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return client\n",
    "    \n",
    "    def gpt_chat(self, content):\n",
    "        completion = self.model.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content,\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        res = completion.choices[0].message.content\n",
    "        return res\n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.chat('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suggest new molecules based on molecule <mol>CCH</mol> and help me decrease the QED value to at most 2.and help me increase the donor value by at least 1.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentence(original_mol,requirements,properties):\n",
    "    sentences = []\n",
    "    for property in properties:\n",
    "        value = requirements[property+'_requ']\n",
    "        property_name = value[\"property\"]\n",
    "        source_smiles = value[\"source_smiles\"]\n",
    "        requirement = value[\"requirement\"]\n",
    "\n",
    "        # Check for specific requirement patterns directly using symbols\n",
    "        if \"increase\" in requirement:\n",
    "            if \">=\" in requirement:\n",
    "                threshold = requirement.split(\">=\")[-1].strip()\n",
    "                sentence = f\"help me increase the {property_name} value by at least {threshold}.\"\n",
    "            elif \">\" in requirement:\n",
    "                threshold = requirement.split(\">\")[-1].strip()\n",
    "                sentence = f\"help me increase the {property_name} value to more than {threshold}.\"\n",
    "            else:\n",
    "                sentence = f\"help me increase the {property_name} value.\"\n",
    "\n",
    "        elif \"decrease\" in requirement:\n",
    "            if \"<=\" in requirement:\n",
    "                threshold = requirement.split(\"<=\")[-1].strip()\n",
    "                sentence = f\"help me decrease the {property_name} value to at most {threshold}.\"\n",
    "            elif \"<\" in requirement:\n",
    "                threshold = requirement.split(\"<\")[-1].strip()\n",
    "                sentence = f\"help me decrease the {property_name} value to less than {threshold}.\"\n",
    "            else:\n",
    "                sentence = f\"help me decrease the {property_name} value.\"\n",
    "\n",
    "        elif \"range\" in requirement:\n",
    "            # Extract the range values from the string\n",
    "            range_values = requirement.split(\",\")[1:]\n",
    "            range_start = range_values[0].strip()\n",
    "            range_end = range_values[1].strip()\n",
    "            sentence = f\"help me keep the {property_name} value within the range {range_start} to {range_end}.\"\n",
    "\n",
    "        elif \"the same\" in requirement:\n",
    "            sentence = f\"help me keep the {property_name} value the same.\"\n",
    "\n",
    "        elif any(op in requirement for op in [\">=\", \"<=\", \"=\", \">\", \"<\"]):\n",
    "            # Directly use the symbols for constraints\n",
    "            sentence = f\"help me ensure the {property_name} value is {requirement}.\"\n",
    "            \n",
    "        else:\n",
    "            sentence = f\"help me modify the {property_name} value.\"\n",
    "        sentences.append(sentence)\n",
    "    sentences = f'Suggest new molecules based on molecule <mol>{original_mol}</mol> and ' + 'and '.join(sentences) \n",
    "    return sentences\n",
    "\n",
    "# Example metadata\n",
    "metadata = {\n",
    "    \"qed_requ\": {\n",
    "        \"source_smiles\": \"O=C([C@H]1CCCC[C@H]1N1CCCC1=O)N1CC2(CC(F)C2)C1\",\n",
    "        \"reference_smiles\": \"NNC(=O)C(=O)NC1CC2(C1)CN(C(=O)[C@H]1CCCC[C@H]1N1CCCC1=O)C2\",\n",
    "        \"property\": \"QED\",\n",
    "        \"requirement\": \"decrease <=2\"\n",
    "    },\n",
    "    \"logp_requ\": {\n",
    "        \"source_smiles\": \"CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1\",\n",
    "        \"reference_smiles\": \"COc1ccc([C@@H](O)C(=O)N[C@H]2[C@@H]3COC[C@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1\",\n",
    "        \"property\": \"logP\",\n",
    "        \"requirement\": \"range, 2, 3\"\n",
    "    },\n",
    "    \"donor_requ\": {\n",
    "        \"source_smiles\": \"O=C(NC[C@H]1CCOc2ccccc21)c1ccc(F)c(C(F)(F)F)c1\",\n",
    "        \"reference_smiles\": \"CC(C)C[NH+](CC(=O)[O-])C(F)(F)c1cc(C(=O)NC[C@H]2CCOc3ccccc32)ccc1F\",\n",
    "        \"property\": \"donor\",\n",
    "        \"requirement\": \"increase >= 1\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# Generate sentences based on metadata\n",
    "generate_sentence('CCH',metadata,['qed','donor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "# Set your OpenAI API key\n",
    "import random\n",
    "import torch\n",
    "from functools import partial\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from tdc.generation import MolGen\n",
    "\n",
    "from eval import get_evaluation\n",
    "import time\n",
    "from model.util import nsga2_selection,so_selection\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def extract_smiles_from_string(text):\n",
    "    pattern = r\"<mol>(.*?)</mol>\"\n",
    "    smiles_list = re.findall(pattern, text)\n",
    "    return smiles_list\n",
    "\n",
    "def split_list(lst, n):\n",
    "    \"\"\"Splits the list lst into n nearly equal parts.\"\"\"\n",
    "    k, m = divmod(len(lst), n)\n",
    "    return [lst[i*k + min(i, m):(i+1)*k + min(i+1, m)] for i in range(n)]\n",
    "\n",
    "class MOO:\n",
    "    def __init__(self, reward_system, llm,property_list,config):\n",
    "        self.reward_system = reward_system\n",
    "        self.config = config\n",
    "        self.llm = llm\n",
    "        self.history = History_Buffer()\n",
    "        self.property_list = property_list\n",
    "        self.moles_df = None\n",
    "        self.pop_size = self.config.get('optimization.pop_size')\n",
    "        \n",
    "    def init_mol_dataset(self):\n",
    "        print('Loading ZINC dataset...')\n",
    "        data = MolGen(name='ZINC')\n",
    "        split = data.get_split()\n",
    "        self.moles_df = split['train']\n",
    "\n",
    "    def generate_initial_population(self, mol1, n):\n",
    "        num_blocks = 200\n",
    "        combs = [[mol1, mol2] for mol2 in self.moles_df.smiles]\n",
    "        combs_blocks = split_list(combs, num_blocks)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(get_evaluation, ['similarity'], block) for block in combs_blocks]\n",
    "            results = [future.result() for future in futures]\n",
    "\n",
    "        combined_results = []\n",
    "        for result in results:\n",
    "            combined_results.extend(result['similarity'])\n",
    "\n",
    "        self.moles_df['similarity'] = combined_results\n",
    "        top_n = self.moles_df.nlargest(n - 1, 'similarity').smiles.values.tolist()\n",
    "        top_n.append(mol1)\n",
    "        return [Item(i,self.property_list) for i in top_n]\n",
    "\n",
    "    def crossover(self, parent_list):\n",
    "        pop_content = self._prepare_pop_content(parent_list)\n",
    "        prompt = generate_sentence(self.original_mol,self.requirement_meta,self.property_list)\n",
    "\n",
    "        prompt = (\n",
    "        prompt + \n",
    "        \"I have some molecules with their objective values. \"\n",
    "        + pop_content +\n",
    "        \" Give me two new molecules that are different from all points above, and not dominated by any of the above. \"\n",
    "        \"You can do it by applying crossover on the points I give to you. \"\n",
    "        f\"Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>{self.original_mol}</mol>. \"\n",
    "        \"Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\"\n",
    "        )\n",
    "        \n",
    "        response = self.llm.chat(prompt)\n",
    "        new_smiles = extract_smiles_from_string(response)\n",
    "        return [Item(smile,self.property_list) for smile in new_smiles],prompt,response\n",
    "\n",
    "    def _prepare_pop_content(self, ind_list):\n",
    "        pop_content = \"\"\n",
    "        for ind in ind_list:\n",
    "            pop_content += f\"<mol>{ind.value}</mol>,\"\n",
    "            for index,property in enumerate(ind.property_list):\n",
    "                pop_content += f\"{property}:{ind.raw_scores[index]},  \"\n",
    "            pop_content += '\\n'\n",
    "        return pop_content\n",
    "\n",
    "    def evaluate(self, smiles_list):\n",
    "        ops = self.property_list\n",
    "        res = self.reward_system.evaluate(ops,smiles_list)\n",
    "        results = np.zeros([len(smiles_list),len(ops)])\n",
    "        raw_results = np.zeros([len(smiles_list),len(ops)])\n",
    "        for i,op in enumerate(ops):\n",
    "            part_res = res[op]\n",
    "            for j,inst in enumerate(part_res):\n",
    "                inst = inst[0]\n",
    "                raw_results[j,i] = inst\n",
    "                if op=='qed':\n",
    "                    if 'increase' in self.requirement_meta['qed_requ']['requirement']:\n",
    "                        results[j,i] = -inst\n",
    "                    else:\n",
    "                        results[j,i] = inst\n",
    "                elif op=='logp':\n",
    "                    logp_requ = self.requirement_meta['logp_requ']['requirement']\n",
    "                    if 'increase' in logp_requ:\n",
    "                        results[j,i] = -inst / 10\n",
    "                    elif 'range' in logp_requ:\n",
    "                        a, b = [int(x) for x in logp_requ.split(',')[1:]]\n",
    "                        mid = (b+a)/2\n",
    "                        results[j,i] = np.clip(abs(inst-mid) * 1/ ( (b-a)/2), a_min=0,a_max=1)    # 2-3    2.5  3-2.5=0.5 * 2     1 0\n",
    "                        #if a<=inst<=b:\n",
    "                        #    results[j,i] = 0\n",
    "                        #else:\n",
    "                        #    results[j,i] = 1     \n",
    "                    else:\n",
    "                        results[j,i] = inst/10\n",
    "                elif op=='donor':\n",
    "                    #print('donor num',inst,donor_num,j,i)\n",
    "                    donor_requ = self.requirement_meta['donor_requ']['requirement']\n",
    "                    donor_num = self.requirement_meta['donor_num']\n",
    "                    if donor_requ == 'increase' and inst - donor_num>0:\n",
    "                        results[j,i] = 0\n",
    "                    elif donor_requ == 'decrease' and donor_num - inst>0:\n",
    "                        results[j,i] = 0\n",
    "                    elif donor_requ == 'same' and donor_num == inst:\n",
    "                        results[j,i] = 0\n",
    "                    elif donor_requ == 'increase, >=2' and inst - donor_num>=2:\n",
    "                        results[j,i] = 0\n",
    "                    else:\n",
    "                        results[j,i] = 1  \n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "        return results,raw_results\n",
    "\n",
    "    def evaluate_all(self,items):\n",
    "        smiles_list = [i.value for i in items]\n",
    "        smiles_list = [[i,smiles_list[0]] for i in smiles_list]\n",
    "        fitnesses,raw_results = self.evaluate(smiles_list)\n",
    "        for i,ind in enumerate(items):\n",
    "            ind.scores = fitnesses[i]\n",
    "            ind.raw_scores = raw_results[i]\n",
    "\n",
    "    def run(self, prompt,requirements):\n",
    "        \"\"\"High level logic\"\"\"\n",
    "        self.requirement_meta = requirements\n",
    "        ngen= self.config.get('optimization.ngen')\n",
    "        \n",
    "\n",
    "        self.init_mol_dataset()\n",
    "        \n",
    "        #initialization \n",
    "        mol = extract_smiles_from_string(prompt)[0]\n",
    "        self.original_mol = mol\n",
    "\n",
    "        population = self.generate_initial_population(mol1=mol, n=self.pop_size)\n",
    "        donor_num = get_evaluation(['donor'], [[mol, mol]])['donor'][0][0]\n",
    "        self.requirement_meta['donor_num'] = donor_num\n",
    "        self.evaluate_all(population)\n",
    "\n",
    "        init_pops = copy.deepcopy(population)\n",
    "\n",
    "        #offspring_times = self.config.get('optimization.eval_budge') // ngen //2\n",
    "        offspring_times = self.pop_size //2\n",
    "        for gen in tqdm(range(ngen)):\n",
    "            offspring = self.generate_offspring(population, prompt, offspring_times)\n",
    "            population = self.select_next_population(population, offspring, self.pop_size)\n",
    "        return init_pops,population\n",
    "\n",
    "    def generate_offspring(self, population, prompt, offspring_times):\n",
    "        offspring = []\n",
    "        #for _ in range(offspring_times): # 20 10 crossver+mutation 20 \n",
    "        parents = [random.sample(population, 2) for i in range(offspring_times)]\n",
    "        while True:\n",
    "            try:\n",
    "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                    futures = [executor.submit(self.crossover, parent_list=parent_list) for parent_list in parents]\n",
    "                    results = [future.result() for future in futures]\n",
    "                    children, prompts, responses = zip(*results) #[[item,item],[item,item]] # ['who are you value 1', 'who are you value 2'] # ['yes, 'no']\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print('retry in 60s, exception ',e)\n",
    "                time.sleep(90)\n",
    "        #parents = random.sample(population, 2)\n",
    "        #children,prompt,response = self.crossover(prompt, parents) \n",
    "        for child_pair in children:\n",
    "            self.evaluate_all(child_pair)\n",
    "            offspring.extend(child_pair)\n",
    "        self.history.push(prompts,children,responses) \n",
    "        return offspring\n",
    "\n",
    "    def select_next_population(self, population, offspring, pop_size):\n",
    "        combined_population = population + offspring\n",
    "        if len(self.property_list)>1:\n",
    "            return nsga2_selection(combined_population, pop_size)\n",
    "        else:\n",
    "            return so_selection(combined_population, pop_size)\n",
    "c,p,r = None,None,None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population size: 4, Evaluation budget: 200\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "class ConfigLoader:\n",
    "    def __init__(self, config_path=\"config.yaml\"):\n",
    "        self.config = self._load_config(config_path)\n",
    "\n",
    "    def _load_config(self, config_path):\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        return config\n",
    "\n",
    "    def get(self, key, default=None):\n",
    "        keys = key.split('.')\n",
    "        value = self.config\n",
    "        for k in keys:\n",
    "            value = value.get(k, {})\n",
    "        if value == {}:\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "config_loader = ConfigLoader(\"config/base.yaml\")\n",
    "\n",
    "pop_size = config_loader.get(\"optimization.pop_size\")\n",
    "eval_budget = config_loader.get(\"optimization.eval_budget\")\n",
    "ngen = config_loader.get(\"optimization.ngen\")\n",
    "qed_requ = config_loader.get(\"optimization.qed_requ\")\n",
    "logp_requ = config_loader.get(\"optimization.logp_requ\")\n",
    "donor_requ = config_loader.get(\"optimization.donor_requ\")\n",
    "model_name = config_loader.get(\"model.name\")\n",
    "\n",
    "print(f\"Population size: {pop_size}, Evaluation budget: {eval_budget}\")\n",
    "\n",
    "class MOLLM:\n",
    "    def __init__(self, config='config/base.yaml'):\n",
    "        self.config = ConfigLoader(config)\n",
    "        self.property_list = self.config.get('goals')\n",
    "        self.reward_system = Rewarding_system()\n",
    "        self.llm = LLM()\n",
    "        self.history = []\n",
    "        self.load_dataset()\n",
    "        self.init_pops = []\n",
    "        self.final_pops = []\n",
    "        self.save_dir = self.config.get('save_dir')\n",
    "        self.save_suffix = self.config.get('save_suffix')\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        with open(self.config.get('dataset.path'), 'r') as json_file:\n",
    "            self.dataset= json.load(json_file)\n",
    "    \n",
    "    def run(self):\n",
    "        for i in range(len(self.dataset['prompts'])):\n",
    "            moo = MOO(self.reward_system, self.llm,self.property_list,self.config)\n",
    "            init_pops,final_pops = moo.run(self.dataset['prompts'][i], self.dataset['requirements'][i])\n",
    "            self.history.append(moo.history)\n",
    "            self.final_pops.append(final_pops)\n",
    "            self.init_pops.append(init_pops)\n",
    "            self.save_to_pkl(os.path.join(self.save_dir,'_'.join(self.property_list) + self.save_suffix +'.pkl'))\n",
    "\n",
    "    def save_to_pkl(self, filepath):\n",
    "        data = {\n",
    "            'history':self.history,\n",
    "            'init_pops':self.init_pops,\n",
    "            'final_pops':self.final_pops\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"Data saved to {filepath}\")\n",
    "\n",
    "    def load_from_pkl(self,filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "        print(f\"Data loaded from {filepath}\")\n",
    "        return obj\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mollm = MOLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ZINC dataset...\n",
      "CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\n",
      "N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)cc2)cc1\n",
      "CC[NH+](CC)[C@](C)(CC)[C@H](O)c1cscc1Br\n",
      "O=C(Nc1nc[nH]n1)c1cccnc1Nc1cccc(F)c1\n",
      "Cc1c(/C=N/c2cc(Br)ccn2)c(O)n2c(nc3ccccc32)c1C#N\n",
      "C[C@@H]1CN(C(=O)c2cc(Br)cn2C)CC[C@H]1[NH3+]\n",
      "CCOc1ccc(OCC)c([C@H]2C(C#N)=C(N)N(c3ccccc3C(F)(F)F)C3=C2C(=O)CCC3)c1\n",
      "Cc1ccccc1C(=O)N1CCC2(CC1)C[C@H](c1ccccc1)C(=O)N2C\n",
      "CCCc1cc(NC(=O)CN2C(=O)NC3(CCC(C)CC3)C2=O)n(C)n1\n",
      "CCH\n"
     ]
    }
   ],
   "source": [
    "## test initialization\n",
    "mol = 'CCH'\n",
    "mollm.moo.init_mol_dataset()\n",
    "init_pops = mollm.moo.generate_initial_population(mol,10)\n",
    "for i in init_pops:\n",
    "    print(i.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test evaluation in MOO\n",
    "mollm.moo.requirement_meta['donor_num'] = 1\n",
    "mollm.moo.evaluate_all(init_pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Item at 0x703ac2c1e250>,\n",
       " <__main__.Item at 0x7039c42151f0>,\n",
       " <__main__.Item at 0x7039c3f5c880>,\n",
       " <__main__.Item at 0x703b14d9db80>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test generation offspring\n",
    "prompt = 'How can we modify the molecule  to decrease its logP value? and still for this molecule Consider a molecule with the SMILES string . Propose changes that could increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like. and still for this molecule  Support me in transforming the molecule  by incorporating the same hydrogen bond donors. This molecule is <mol>CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)CCl)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12</mol>'\n",
    "offs = mollm.moo.generate_offspring(init_pops, prompt, 2)\n",
    "offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)C(Cl)CCl)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12\n",
      "CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)C(O)N1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12\n",
      "CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)C(=O))C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12\n",
      "CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(OH)CCl)C1)Nc1nc(-c2ccc(C=N)c(F)c2)cn2ccnc12\n"
     ]
    }
   ],
   "source": [
    "for i in offs:\n",
    "    print(i.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.82714972]\n",
      "[-0.82237984]\n",
      "[-0.81871365]\n"
     ]
    }
   ],
   "source": [
    "## test selection next generation\n",
    "next_gen = mollm.moo.select_next_population(init_pops, offs, 3)\n",
    "for i in next_gen:\n",
    "    print(i.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overall \n",
    "mollm.moo.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['history', 'init_pops', 'final_pops'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoint\n",
    "import pickle\n",
    "with open('/home/v-nianran/src/results/qeduniform150.pkl','rb') as f:\n",
    "    file = pickle.load(f)\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.095171701744179, 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdc import Oracle\n",
    "oracle = Oracle(name = 'LogP')\n",
    "\n",
    "oracle(['c1ccccc1','CCH'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1',\n",
       " 'CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)CCl)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12',\n",
       " 'CCOc1cc(C)ccc1Cn1c(-c2cccc(C)n2)nnc1N1CCN(S(C)(=O)=O)[C@@H](C)C1',\n",
       " 'CCC1Cc2c(nn(-c3ccc4ccccc4c3)c2-c2cc(Cl)cc(Cl)c2)C(CC)N1C(=O)c1cccc(-n2cnnc2)c1',\n",
       " 'CC1Oc2ccc(-c3cn4ccsc4n3)cc2N(C(Cc2cccs2)C(CCl)C(=O)c2ccc(-c3ccccc3)cc2)C1=O',\n",
       " 'Cc1cccc(C2CCCCCN2S(=O)(=O)c2cccc3nsnc23)c1',\n",
       " 'CCC(C)=C(CC)CCC(=O)NC1CCN(C2CCN(C(=O)[C@H]3CC[C@H](C(=O)OC)C3)CC2)CC1',\n",
       " 'CCCc1ccc(-c2ccc([C@H](O)C[C@H]3CCCN3C[C@@H]3CCC4(CCCC4)O3)cc2)s1',\n",
       " 'CC(C)(C)c1nc([NH2+]c2nc(Nc3ccc4c(c3)CNCC4(C)C)ncc2C(O)NC2CC2)cs1',\n",
       " 'CCc1cc2c(CN3CCN(C(=O)c4cccs4)CC3)cc(=O)oc2cc1-c1c(C)cc(C)cc1C',\n",
       " 'COc1cc(C(=O)OCCN2CCO[C@H](C)C2)ccc1[N+](=O)[O-]',\n",
       " 'CCOc1ccccc1CCCNC(=O)c1ccccc1SCc1ccccc1',\n",
       " 'O=C(CCc1ccc[nH]1)N1CC[C@]2(C1)CN(C(=O)C1=COCC1)CCN2C(=O)Oc1c(Cl)cc(-c2ccccc2)cc1Cl',\n",
       " 'O=C(CCCCN1CCCCCC1)c1ccc2nc(Cc3ccccc3)c(=O)n(Cc3ccc(F)cc3)c2n1',\n",
       " 'C[C@@H](F)CCN1CC[C@H]1CNC(=O)c1ccnn1CC1CCC1',\n",
       " 'C=CC=CC(C(=O)OC1CN2C(N)=NC(C(CCl)C(O)Cc3cccs3)C3[NH+]=C(N)NC32C1(O)O)=C1C=CC=CC1',\n",
       " 'CC(NC(C)C(=O)c1ccccc1)C(=O)NC(=O)Cc1cc(F)cc(F)c1',\n",
       " 'C=CC1OC(=O)N(Cc2ccccc2)C1C(C#Cc1ccccc1)Sc1ccc(C)cc1',\n",
       " 'C[C@@H]1CCC[C@@H](CNC(=O)C(=O)Nc2nc(C(F)(F)NC(=O)C(=O)NN)cs2)C1',\n",
       " 'COCC[C@H](NC(=O)N1CCC[C@H]1c1nncn1C)C(C)(C)C',\n",
       " 'N#Cc1cccnc1NCCCc1nc(-c2ccc(F)cc2)no1',\n",
       " 'CCOC(=O)c1cc2cc3c(cc2nc1NC(=O)Nc1ccc(NC)cc1)OCO3',\n",
       " 'CC(C)(C)OC(=O)N1CCC(CC(=O)N2CCC(C3CCN(C4c5ccc(-c6ccc7ccccc7c6)c(Br)c5CCc5cc(Br)cnc54)CC3)CC2)CC1',\n",
       " 'C/C(=C/c1ccccc1)CN(C)c1nnc(CC[C@@H]2CCCO2)n1C',\n",
       " 'CCC(CC)N(CCN)C(=O)c1ccc(C)cc1F',\n",
       " 'CCNC(=NCc1cccc(OC)c1)NCc1c(C)nn(C)c1C',\n",
       " 'Cc1ccc(S[C@H](c2ccccc2)[C@H](C)NC(=O)NCC(C)(C)c2ccc(Cl)cc2)cc1',\n",
       " 'C=C(NC(=O)OC(C)(C)C)C(CCCCCC)C(=O)N1CCC([C@H]2CCCCN2C(=O)CC(C)(C)C)CC1',\n",
       " 'C=CC(C)SOSC(CC)C(C)C(=O)NC[C@@H]1CCN(C(=O)c2cc3ccc(OC)cc3[nH]2)[C@H]1c1cccnc1',\n",
       " 'C[C@@H]([NH2+][O-])C(=O)N1C[C@@H](N)[C@H](c2cccc(F)c2)C1',\n",
       " 'CNC(=O)C(CN1CCC(c2ccccc2)C1)NC(=O)c1ccc(OC(C)C)c(Cl)c1',\n",
       " 'Cc1[nH]nc(-c2ccc3ccccc3c2)c1S(=O)(=O)N1CCC[C@@H](C(=O)Nc2cccc(C(=O)N3CCCC3)c2)C1',\n",
       " 'Cc1ccc(CN2Cc3ccnn3CCC2CC(C)c2cccc(Oc3ncccn3)c2)o1',\n",
       " 'O=C(CCCCCn1c(=S)[nH]c2ccc(N3CCOCC3)cc2c1=O)NCCc1ccccc1Cl',\n",
       " 'COCc1noc(CN2CCN(C(=O)N[C@H](C)COc3ccccc3C(F)(F)F)CC2)n1',\n",
       " 'CC(C)c1cccc(N(C)c2ccc(C(F)(F)F)cc2NC(=O)C=Cc2ccco2)c1',\n",
       " 'CCc1nn(C)cc1NC(=O)NCc1nc(C(F)(F)F)no1',\n",
       " 'CC(C)c1cccc(Oc2cc(NC(=O)N3CC[C@@H](N4CCCC4)[C@@H]3C)ccn2)c1',\n",
       " 'CC(C)c1cccc(NS(=O)(=O)c2nc3ccc(Oc4c(Br)cc(CC(F)C(=O)O)cc4Br)cc3[nH]2)c1',\n",
       " 'CCCCCC(CCC1CCC2Cc3c(cccc3OCC)CC12)Sc1ccc(C)cc1',\n",
       " 'CCC(Cc1ccc(OC(C)=O)cc1)=C(CC)[C@H](C)OCc1ccccc1',\n",
       " 'CN(C)CCCN1C(=O)C2C3C=C(C(O)(c4ccccc4)c4ccccn4)C(C3=C(c3ccccc3)c3ccccn3)C2C1=O',\n",
       " 'CCC[NH+](CC(=O)N1CCc2ccccc21)c1cc(Br)sc1C(=O)Nc1ccccc1OC',\n",
       " 'CN1CC[NH+](Cc2cc(-c3cccc(OCc4ccccc4)c3)c3c(N)ncnn23)CC1',\n",
       " 'CC(C)N(C)CC(=O)N1CC[C@@H](CNC(=O)CCNC(=O)c2ccccc2)[C@H]1c1cccnc1',\n",
       " 'CC(C)CC(=O)N1CCC[C@H]1CNC(=O)c1sccc1C(F)F',\n",
       " 'CC(N)=[NH+]CCn1cc(-c2cccc(C(N)=S)c2)c2ccc(CO)cc21',\n",
       " 'C[C@H](c1ccccc1)N(C)C(=O)CN(C)c1nnc([C@@H]2CCC(=O)N2)n1C[C@@H]1CCCOC1',\n",
       " 'CC(C)CC[C@@H]1CCCCN1C(=O)c1ccc(Oc2cccc(C(C)C)c2)cc1OC(F)F',\n",
       " 'CCN(CC)c1ccc(-c2nnc(SCc3cc(=O)oc4cc(C)c(C)cc34)o2)cc1',\n",
       " 'Cc1cccc(C(=O)N(C)C2CN(C(=O)[C@@H]3CCCC34CC4)C2)c1C',\n",
       " 'CN(C)CC1=CC=CC1c1ccc2ccccc2c1N=[N+]=[N-]',\n",
       " 'CCCCn1ncc(NC(=O)N[C@H](C)CCC(CC)=C(CC)C(C)C)c1C',\n",
       " 'CCOC(=O)C[C@@H](CNc1ccc(S(C)(=O)=O)cc1)CC(C)C',\n",
       " 'CCOC(=O)c1csc([C@@H](C#N)C(=O)c2ccccc2N(C)c2ccccc2)n1',\n",
       " 'O=C(CCc1ccccc1C1CCCCCCC1)N1CCC[C@H](c2nc3ccccc3o2)C1',\n",
       " 'COc1ccc(C(=O)CCC(=O)N[C@H]2[C@@H]3COC[C@H]2CN(C(=O)c2cc(O)n(C)n2)C3)cc1',\n",
       " 'C=CC[C@H](CNC(=O)N[C@H](c1ccc(F)cc1)C1CCC1)CSc1ccc(C)cc1',\n",
       " 'CC(C)CC(NC(=O)OCNc1cc(Cl)ccc1Cl)C(=O)NC1CCC2CN(S(=O)(=O)c3cccc(C(F)(F)F)c3)CC21',\n",
       " 'COCc1c[nH]c(C(=O)N2CC[C@H](CNC(=O)Cc3ccc(C(=O)OC)s3)[C@@H]2c2cccnc2)c1',\n",
       " 'CC(C)c1cccc(Oc2ccc(C=NNC(=O)c3cccc4ccccc34)cc2OCc2ccc(Cl)cc2Cl)c1',\n",
       " 'CCC(C)=C(CC)[C@@H](NC1CC(C#N)(c2ccccc2)C1)c1ccccc1',\n",
       " 'C[C@H](CNC(=O)C(C)(C)c1ccc2ccccc2c1)CN1CCCCC1',\n",
       " 'COCCOc1ccc(-c2n[nH]c(C)c2CSC(C)(C)C)cc1',\n",
       " 'CS(=O)(=O)c1ccc(C(=O)N2CCN(c3nnnn3-c3ccccc3)CC2)cc1',\n",
       " 'C=C(C)CCN1C[C@@H]2CCCN(C(=O)c3ccsc3)[C@@H]2C1',\n",
       " 'CCC(NC(=O)CN1CCN(C(=O)c2cccs2)CC1)c1ccc(C)cc1',\n",
       " 'CN(C)S(=O)(=O)N1CC[C@@H]2CN(C(F)(F)Cc3nc4c(Cl)ncnc4s3)C[C@H]2C1',\n",
       " 'O=C([O-])COCSCCCN1CCC[C@H]1C[C@H](O)c1cccs1',\n",
       " 'Cc1cc(CC(=O)NCC2CCCN(Cc3cc(=O)n4ccccc4n3)C2)on1',\n",
       " 'CCC(Br)c1ccc(-c2ccc(C(C)(C)C)cc2)c(NC(=O)CN(c2ccc(OC)cc2OC)S(C)(=O)=O)c1',\n",
       " 'O=C([O-])COCOc1ccccc1CNC(=O)[C@]12CCC[C@@H]1C2',\n",
       " 'CCc1oc2ccccc2c1CN1CCCCN(C)C(=O)C(C)NC(=O)COc2cc(O)cc(c2)C(=O)NCCC1',\n",
       " 'CCCCC(CC)COCOc1cccc([C-]2C3CC=CC3[C+](c3cccc(OC)c3)C2(C)C)c1',\n",
       " 'O=C(CCOc1ccc(F)cc1)N1CCO[C@@]2(CCN(C(=O)c3cnc4c(c3)CCNCC4)C2)C1',\n",
       " 'Cc1cccc(OCC(=O)NC(CC(=O)O)c2ccc(OC(F)(F)NC(=O)C(=O)NN)cc2)c1',\n",
       " 'Cc1cccc(CCC(=O)N2CCO[C@]3(COCCN(C(=O)COc4ccccc4)C3)C2)n1',\n",
       " 'CC(C)C[NH+](CC(=O)[O-])C(F)(F)Oc1ccc(NC(=O)c2cnc(N3CCC(C)C3)c(-c3ccc(F)nc3)c2)cc1',\n",
       " 'COc1cc(OC)c2cc(CCCN[C@@H](C)CCC3CC3)[nH]c2c1',\n",
       " 'Cc1ccc(C(=O)C=Cc2ccc(CC(C)c3cccc(Oc4cc(C)c(Cl)c(C)c4)c3)o2)s1',\n",
       " 'CC(Cc1cncc(Br)c1)c1ccc(CC(=O)N2C[C@@H]3COC[C@H](C2)[C@@H]3NC(=O)c2cc3c(n2C)-c2ncccc2OC3)nc1',\n",
       " 'Cc1cc2c(C(C)C)c(O)c(O)c(C=Nc3c(C)n(C)n(-c4ccccc4)c3=O)c2c(O)c1-c1c(C)cc2c(C(C)C)c(O)c(O)c(C=Nc3c(C)n(C)n(-c4ccccc4)c3=O)c2c1O',\n",
       " 'CC(C)OCCCN1C(=O)c2oc3ccc(Cl)cc3c(=O)c2C1c1cccc(Cl)c1',\n",
       " 'CC[NH+]1CCN(c2ccccc2NC(=O)c2ccc(-c3nnc(-c4cc(C(N)=[NH+]O)ccc4C)o3)cc2)CC1',\n",
       " 'NC(=O)CSc1ccccc1NC(=O)Cc1cnn(-c2ccccc2)c1',\n",
       " 'CCC(C)NC(=O)c1cc(-c2cccc(OC)c2)nc2cc(-c3ccccc3)nn12',\n",
       " 'Cc1cccc(CCC(Cc2ccn(C(C)C)n2)SC(C)(C)C)c1',\n",
       " 'CCCCC(CC)COCOc1nc(C)c(-c2ccc(C(=O)NCc3ccccn3)s2)cc1CC',\n",
       " 'CNC(=O)[C@@H]1CN(c2nnc(CC3CCCC3)n2CCOc2ccc(F)c(Cl)c2)CCO1',\n",
       " 'CCCCC(CC)COCOc1ccc(NC(=O)NCc2ccc([C@@H]3C[C@@H]3C)o2)c([N+](=O)[O-])c1',\n",
       " 'CC(C)(c1ccccn1)C(CC(=O)O)Nc1nc(-c2c[nH]c3c(F)cc(F)cc23)ncc1F',\n",
       " 'Cc1coc(C(N=C2NS(=O)(=O)N=C2Nc2cccc(S(=O)(=O)N(C)C)c2O)C(C)(C)C)c1',\n",
       " 'CC1CC(C(=O)[O-])C[NH+](C(F)(F)c2cccc(CN(Cc3nc(Cc4ccccc4)no3)[C@@H](C)C#N)c2)C1',\n",
       " 'Cc1cc(C)c(C(C)c2ccc(CNC(=O)N3CCC(c4ccccc4)C3)cc2)c(C)c1',\n",
       " 'CC(=O)OCC1=C(C(=O)[O-])N2C(=O)C(NC(=O)C(N)c3ccc(-c4c(C)cc(C)cc4C)cc3)C2SC1',\n",
       " 'CCCCC(CC)COCOC(=O)CN(Cc1ccccc1C)C(=O)COc1ccc(C#N)cc1OC',\n",
       " 'C[C@@H](C(=O)N1[C@H]2C[C@@H]([C@H](F)C2)[C@@H]1C(N)=O)c1ccccc1Cl',\n",
       " 'COC(=O)c1ccc(N2C(=O)CC(N(C(=O)c3ccccc3C)C3CCCC3)C2=O)cc1',\n",
       " 'CCC[C@H](C(=O)N1CCC[C@@H](c2nnc(Sc3ccc(C)cc3)o2)C1)c1ccccc1',\n",
       " 'O=C(N[C@H]1C[C@H]2CC[C@@H](C1)N2C(=O)[C@@H]1C[C@H](O)CN1C(=O)OCc1ccccc1)[C@@H]1[C@H]2C=CS[C@@H]21',\n",
       " 'C[C@H](NCC1CC1)[C@@H]1CN(C(=O)C2(C(F)F)CCC2)CCO1',\n",
       " 'Cc1ccccc1-n1cnnc1SCC(=O)Nc1c(C#N)c2c(n1-c1ccccc1)CCCC2',\n",
       " 'CCc1ccccc1O[C@@H](C(=O)N1CCC(C(N)c2ccc(Cl)cc2)CC1)c1ccccc1',\n",
       " 'CC(C)(C)OC(=O)NCC(=O)NC1CCN(C(=O)c2cc(C3CCCCCCC3)on2)CC1',\n",
       " 'COc1ccc(C(=O)N2CC[C@@H]2CNC(=O)C(C)(C)C(C)C)cc1C',\n",
       " 'CC(C)N1CC[C@H](N(C)C(=O)c2ccc(O[C@H](C)c3ccccc3)cc2)C1',\n",
       " 'CC(C)c1cccc(OC[C@@H]2CN(c3nnc(-c4cnn(C)c4)n3Cc3ccc(OC(F)F)c(F)c3)C[C@@H](C)O2)c1',\n",
       " 'O=c1[nH]c2ncnc(N3CCC(c4nc(-c5ccc(F)c(F)c5)cn4CCN4CCCC4)CC3)c2[nH]1',\n",
       " 'Nc1ccccc1-[n+]1cc(=O)n(-c2ccc(C(F)(F)F)cc2)[nH]1',\n",
       " 'Cc1cccc(Oc2cc(-c3nc(-c4cccc(-c5csc(C6CC6)n5)c4)no3)c(Br)s2)c1',\n",
       " 'O=C(NC[C@H]1CCN(C(=O)c2cccn3cncc23)[C@H]1c1cccnc1)c1cnc(O)nc1O',\n",
       " 'CCc1cc(-c2cccc(C#N)c2)nn1-c1cc(Cl)c(C(=O)N2CCN(c3ccccn3)CC2)c(Cl)c1',\n",
       " 'CC(C)[C@H](C)C(=O)N[C@@H](C)CCCNc1ncc(C(=O)O)cn1',\n",
       " 'CC1CCC(C(=O)N(c2cc(-c3cnc(N)c(C4CCCCCCC4)c3)sc2C=O)C(C)C)CC1',\n",
       " 'CC[NH2+]C(CN(c1cc(C(=O)Cc2cc(-n3ccnc3)cc(C(F)(F)F)c2)ccc1C)c1cnc2ccccn12)C(=O)[O-]',\n",
       " 'COc1ccc2c(C)c(CC(=O)N3CCN(CCc4ccncc4)CC3)c(=O)oc2c1OC',\n",
       " 'COC(=O)c1c(NC(=O)CSc2nnnn2-c2cc(C)ccc2OC)sc(C)c1C',\n",
       " 'CC(C)c1cccc(OC(=O)[C@H](Cc2cccc(S(C)(=O)=O)c2)N[C@H]2C[C@H](C)N(C(=O)OC(C)(C)C)[C@H](C)C2)c1',\n",
       " 'CC(C)C[NH+](CC(=O)[O-])C(F)(F)c1ccc(C(=O)N2C[C@@H]3COC[C@H](C2)[C@@H]3NC(=O)c2c(F)ccc(O)c2F)[nH]1',\n",
       " 'CC(C)c1cccc(OC[C@@H]2CN(c3nnc(CN4CCCC4=O)n3Cc3ccnc(OCC(F)(F)F)c3)C[C@H](C)O2)c1',\n",
       " 'CC(CBr)(CBr)CC1CC(C(=O)NCCc2ccccc2)N(C(=O)OCc2ccccc2)C1',\n",
       " 'COC(=O)c1cc(C)c(S(=O)(=O)Nc2ncc(Br)nc2OCc2ccccc2)s1',\n",
       " 'CCCCC(CC)COCOc1cc(Cl)c(OC)cc1NC(=O)CCNCCc1ccc(OC)cc1',\n",
       " 'CCCc1ccc(-c2ccccc2C(=O)NC(=S)N2CCN(c3ccccc3F)CC2)s1',\n",
       " 'CCc1sc2ncnc(NC3CCC(N(C)CNc4cc(Cl)ccc4Cl)CC3)c2c1C1=Cc2ccccc2C1',\n",
       " 'CCOc1ccc(N2C(=O)C(=O)C(=C(O)c3ccc(OCC)cc3OCC)C2c2ccccc2)cc1',\n",
       " 'CCC(C)c1cccc(Oc2cc(CN3Cc4ccccc4[C@@H]4CNC[C@@H]43)ccc2F)c1',\n",
       " 'Cc1cc(Cl)cc(Cl)c1Oc1ccccc1NC(=S)NN1C(=O)NC(C)(c2ccc([N+](=O)[O-])cc2)C1=O',\n",
       " 'O=C(O)Cn1c(-c2ccccc2)c(Cl)nc(NCc2cc(F)ccc2F)c1=O',\n",
       " 'Cc1ccc(C2(C(=O)N[C@H]3CCC(C)(C)C[C@@H]3C)CC2)cc1Oc1cccc(C(C)C)c1',\n",
       " 'CN(CCC(=O)N[C@@H]1CC12CCN(C(=O)[C@@H]1CC13CCC3)CC2)NS(C)(=O)=O',\n",
       " '[NH3+]CNC(=O)N1CCC(C(=O)c2ccc3[nH]c(=O)oc3c2)CC1',\n",
       " 'CC(C)NS(=O)(=O)c1ccc(C(N)=[NH+]O)cc1NC(=O)[C@@H](C)OC(=O)[C@@H](C)Oc1cccc(F)c1',\n",
       " 'CC(C)[C@H](NC(=O)c1cc(-c2ccco2)[nH]n1)[C@@H](O)c1ccccc1',\n",
       " 'CC(C(=O)Nc1ccc(F)c([N+](=O)[O-])c1)n1nc(-c2ccc(Oc3cc4cc(F)ccc4s3)cc2)ccc1=O',\n",
       " 'CCCCC(CC)COCOC1CCC(NCC2CC(=O)N(CCOC)C2c2cnn(C)c2)CC1',\n",
       " 'CC(=O)c1sc(C2C(C)CCCN2C(=O)c2ccc(C)cc2-c2ncccn2)c(Nc2nc3ccc(F)cc3o2)c1C',\n",
       " 'COC12CC(COS(=O)(=O)c3ccc(C)cc3)CN(C)C1Cc1c[nH]c3cccc2c13',\n",
       " 'COc1ccc2ccccc2c1Cn1cnc2sc3c(c2c1=O)CCC(NCCNC(C)=O)C3',\n",
       " 'CCCCC(CC)COCOc1c(C=NNC(=O)c2cc(Cl)ccc2O)ccc(OC)c1OC',\n",
       " 'Cc1ccc2nc(CSc3nnc(-c4ccccc4Cl)n3C3CCCC3)cc(=O)n2c1',\n",
       " 'CC(C)C[NH+](CC(=O)[O-])C(F)(F)C1(C(=O)Nc2nc3c(s2)C[C@@H](NC(=O)c2cnn4cccnc24)CC3)CC1',\n",
       " 'NC(Cc1ccccc1)C(=O)N1CCC(Oc2ccc(F)cc2F)CC1',\n",
       " 'CC(C)c1cccc(Sc2c(-c3cc(-c4ccccc4)nn3-c3ccccc3)c(=O)oc3c2cnc2ccccc23)c1',\n",
       " 'CC[C@@H](C[C@@H](C)CO)NC(=O)Nc1ccc(C)c(NC(C)=O)c1C',\n",
       " 'CC(=O)c1ccc2c(C3(C(=O)[O-])CCC3)c3n(c2c1)CCCc1c-3ccc2[nH]c(-c3cc(C)sc3C)cc12',\n",
       " 'Cc1nnc(N2CCC([C@](C)(O)C(F)(F)F)CC2)n1Cc1ccccc1CN1CC[C@@H](O)C1',\n",
       " 'CCC(Br)c1ccc(C(=O)N2CC[C@@]3(CN(C(=O)Cc4cn5c(nc4=O)SCC5)CCO3)C2)c(-c2ccccc2)c1',\n",
       " 'COc1ccccc1CN(C)c1cnc2[nH]ccc2c1N(C=O)C(C)C',\n",
       " 'CCC(C)c1cccc(Oc2ccc(C=C3N=C(c4ccc(Br)cc4)N(c4ccc(C)cc4)C3=O)cc2)c1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "donor_df = pd.read_csv('/home/v-nianran/src/data/dpo_donor_test.csv')\n",
    "qed_df = pd.read_csv('/home/v-nianran/src/data/dpo_qed_test.csv')\n",
    "logp_df = pd.read_csv('/home/v-nianran/src/data/dpo_logp_test.csv')\n",
    "\n",
    "def extract_smiles_from_string(text):\n",
    "    pattern = r\"<mol>(.*?)</mol>\"\n",
    "    smiles_list = re.findall(pattern, text)\n",
    "    return smiles_list\n",
    "num = 50\n",
    "df = pd.concat([logp_df.iloc[:num],qed_df.iloc[num:num*2],donor_df.iloc[num*2:num*3]])\n",
    "moles = [extract_smiles_from_string(p)[0] for p in df.prompt]\n",
    "moles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,\n",
       " 'How can we modify the molecule  to decrease its logP value? and still for this molecule Consider a molecule with the SMILES string . Propose changes that could increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like. and still for this molecule  Support me in transforming the molecule  by incorporating the same hydrogen bond donors. This molecule is <mol>CC=C(C=CC(=C(C)CC)N1CCOC(C(Cc2cccs2)C(O)CCl)C1)Nc1nc(-c2ccc(C=N)c(N)c2)cn2ccnc12</mol>')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_prompt = []\n",
    "for index,mol in enumerate(moles):\n",
    "    new_p = re.sub(r'<mol>.*?</mol>', '', logp_df.prompt[index]) + ' and still for this molecule ' +  \\\n",
    "        re.sub(r'<mol>.*?</mol>', '', qed_df.prompt[index]) + ' and still for this molecule  ' +\\\n",
    "        re.sub(r'<mol>.*?</mol>', '', donor_df.prompt[index]) + f' This molecule is <mol>{mol}</mol>'\n",
    "    combine_prompt.append(new_p)\n",
    "len(combine_prompt),combine_prompt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'source_smiles': 'CC(Cc1cncc(Br)c1)c1ccc(CC(=O)N2C[C@@H]3COC[C@H](C2)[C@@H]3NC(=O)c2cc3c(n2C)-c2ncccc2OC3)nc1',\n",
       "  'reference_smiles': 'Cn1c(C(=O)N[C@H]2[C@@H]3COC[C@H]2CN(C(=O)Cc2ccc(O)cn2)C3)cc2c1-c1ncccc1OC2',\n",
       "  'property': 'QED',\n",
       "  'requirement': 'increase'},\n",
       " {'source_smiles': 'C=C(C)C(c1ccccc1OCc1cccc(C(=O)NC(C)c2cccc(Br)c2)c1)C(C)(F)Br',\n",
       "  'reference_smiles': 'CC(NC(=O)c1cccc(COc2ccccc2C(N)=O)c1)c1cccc(Br)c1',\n",
       "  'property': 'logP',\n",
       "  'requirement': 'range, 4, 5'},\n",
       " {'source_smiles': 'CC(C)(C)c1cc(C(N)=[NH+]O)ccc1C(=O)NN1CC(C(=O)OCC(=O)c2ccc(Cl)cc2Cl)CC1=O',\n",
       "  'reference_smiles': 'CC(C)(C)c1ccc(C(=O)NN2CC(C(=O)OCC(=O)c3ccc(Cl)cc3Cl)CC2=O)cc1',\n",
       "  'property': 'donor',\n",
       "  'requirement': 'decrease, >=2'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/home/v-nianran/src/data/test_qed.metadata.json','r') as f:\n",
    "    qed_meta = json.load(f)\n",
    "with open('/home/v-nianran/src/data/test_logp.metadata.json','r') as f:\n",
    "    logp_meta = json.load(f)\n",
    "with open('/home/v-nianran/src/data/test_donor.metadata.json','r') as f:\n",
    "    donor_meta = json.load(f)\n",
    "qed_meta[80],logp_meta[80],donor_meta[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'prompts':combine_prompt,\n",
    "    'requirements':[\n",
    "        {'qed_requ': qed_meta[i],\n",
    "        'logp_requ': logp_meta[i],\n",
    "        'donor_requ': donor_meta[i]} for i in range(len(combine_prompt))\n",
    "    ]\n",
    "}\n",
    "json_file_path = 'data/uniform150_test.json'\n",
    "\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qed_requ': {'source_smiles': 'O=C([C@H]1CCCC[C@H]1N1CCCC1=O)N1CC2(CC(F)C2)C1',\n",
       "  'reference_smiles': 'NNC(=O)C(=O)NC1CC2(C1)CN(C(=O)[C@H]1CCCC[C@H]1N1CCCC1=O)C2',\n",
       "  'property': 'QED',\n",
       "  'requirement': 'decrease'},\n",
       " 'logp_requ': {'source_smiles': 'CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1',\n",
       "  'reference_smiles': 'COc1ccc([C@@H](O)C(=O)N[C@H]2[C@@H]3COC[C@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1',\n",
       "  'property': 'logP',\n",
       "  'requirement': 'range, 2, 3'},\n",
       " 'donor_requ': {'source_smiles': 'O=C(NC[C@H]1CCOc2ccccc21)c1ccc(F)c(C(F)(F)F)c1',\n",
       "  'reference_smiles': 'CC(C)C[NH+](CC(=O)[O-])C(F)(F)c1cc(C(=O)NC[C@H]2CCOc3ccccc32)ccc1F',\n",
       "  'property': 'donor',\n",
       "  'requirement': 'increase'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(json_file_path, 'r') as json_file:\n",
    "    new_data = json.load(json_file,)\n",
    "new_data['requirements'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data['prompts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ZINC dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCn1cc(NC(=O)C2CCN(C(=O)CCc3ccccc3Cl)CC2)cn1</mol>,qed:0.8245023098421231,  \n",
      "<mol>COC(=O)[C@@H](c1ccccc1Cl)N1CCN(C(=O)CCc2ccccc2Cl)CC1</mol>,qed:0.6444932819174114,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n",
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>,qed:0.21636799460509812,  \n",
      "<mol>CCn1cc(NC(=O)C2CCN(C(=O)CCc3ccccc3Cl)CC2)cn1</mol>,qed:0.8245023098421231,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:06,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCCCC(CC)COCOc1ccc(C(=O)NC2CCC3C(COc3ccccc3Cl)CCC2C3)cc1</mol>,qed:0.229442435633374,  \n",
      "<mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>,qed:0.21636799460509812,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n",
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N2CCN(C(=O)CCc3ccccc3Cl)CC2)cc1</mol>,qed:0.25957177248241287,  \n",
      "<mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>,qed:0.21636799460509812,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCCCC(CC)COCOc1ccc([C@@H](CO)C(=O)N[C@@H]2CCC3C(COc3ccccc3Cl)CCC2C3)cc1</mol>,qed:0.18847463002625045,  \n",
      "<mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>,qed:0.21636799460509812,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n",
      "Suggest new molecules based on molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol> and help me decrease the QED value.I have some molecules with their objective values. <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N2CCN(C(=O)CCc3ccccc3Cl)CC2C3CCOCC3)cc1</mol>,qed:0.19109185820881366,  \n",
      "<mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>,qed:0.21636799460509812,  \n",
      " Give me two new molecules that are different from all points above, and not dominated by any of the above. You can do it by applying crossover on the points I give to you. Please note when you try to achieving these objectives, the molecules given you propose should be similar to the original molecule <mol>CCCCC(CC)COCOc1ccc([C@@H](O)C(=O)N[C@@H]2[C@H]3COC[C@@H]2CN(C(=O)CCc2ccccc2Cl)C3)cc1</mol>. Do not write code. Do not give any explanation. Each output new molecule must start with <mol> and end with </mol> in SIMLE form\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:08<00:04,  4.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mollm \u001b[38;5;241m=\u001b[39m MOLLM(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig/base.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmollm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 53\u001b[0m, in \u001b[0;36mMOLLM.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompts\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m     52\u001b[0m     moo \u001b[38;5;241m=\u001b[39m MOO(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_system, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperty_list,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m---> 53\u001b[0m     init_pops,final_pops \u001b[38;5;241m=\u001b[39m \u001b[43mmoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrequirements\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend(moo\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_pops\u001b[38;5;241m.\u001b[39mappend(final_pops)\n",
      "Cell \u001b[0;32mIn[22], line 178\u001b[0m, in \u001b[0;36mMOO.run\u001b[0;34m(self, prompt, requirements)\u001b[0m\n\u001b[1;32m    176\u001b[0m offspring_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(ngen)):\n\u001b[0;32m--> 178\u001b[0m     offspring \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_offspring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffspring_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_next_population(population, offspring, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m init_pops,population\n",
      "Cell \u001b[0;32mIn[22], line 190\u001b[0m, in \u001b[0;36mMOO.generate_offspring\u001b[0;34m(self, population, prompt, offspring_times)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    189\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrossover, parent_list\u001b[38;5;241m=\u001b[39mparent_list) \u001b[38;5;28;01mfor\u001b[39;00m parent_list \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[0;32m--> 190\u001b[0m     results \u001b[38;5;241m=\u001b[39m [future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures]\n\u001b[1;32m    191\u001b[0m     children, prompts, responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults) \u001b[38;5;66;03m#[[item,item],[item,item]] # ['who are you value 1', 'who are you value 2'] # ['yes, 'no']\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 190\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    189\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrossover, parent_list\u001b[38;5;241m=\u001b[39mparent_list) \u001b[38;5;28;01mfor\u001b[39;00m parent_list \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[0;32m--> 190\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures]\n\u001b[1;32m    191\u001b[0m     children, prompts, responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults) \u001b[38;5;66;03m#[[item,item],[item,item]] # ['who are you value 1', 'who are you value 2'] # ['yes, 'no']\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mollm = MOLLM('config/base.yaml')\n",
    "mollm.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
